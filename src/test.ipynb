{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from param import parse_args\n",
    "from multitask_reg import Trainer\n",
    "from reg_data import RefCOCOGenerationFineTuneDataset, get_loader\n",
    "import json\n",
    "from refcoco_utils import REFER\n",
    "\n",
    "def test(dataset='refcoco+', split='testB', task='REG', epoch=0, lr=None, save_name=None):\n",
    "\n",
    "    args = parse_args()\n",
    "    args.gpu = 0\n",
    "    args.train = 'val'\n",
    "    args.num_beams = 5\n",
    "    args.batch_size = 1\n",
    "    args.dataset = dataset\n",
    "    split_map = {'refcoco+': 'unc',\n",
    "                 'refcoco': 'unc',\n",
    "                 'refcocog': 'umd'}\n",
    "    args.dataset_split = split_map[args.dataset]\n",
    "    if lr:\n",
    "        args.load = '/sharefs/baai-mrnd/yfl/codebase/Dialog/snap'+args.dataset+'/' + task + '/' + lr + '/' + str(epoch)\n",
    "    else:\n",
    "        args.load = '/sharefs/baai-mrnd/yfl/codebase/Dialog/snap'+args.dataset+'/' + task + '/' + str(epoch)\n",
    "    args.rl_training = False\n",
    "    args.use_rec = True\n",
    "    args.experiment_name = '2022.11.09'\n",
    "    args.dialog_training = True\n",
    "    args.dialog_round = 5\n",
    "    args.zero_shot_test = True\n",
    "    args.last_round = True\n",
    "    args.use_detector = True\n",
    "    # args.refine = False\n",
    "    args.test_threshold = 0.5\n",
    "    args.dialog_sp_training = True\n",
    "    # args.refine_load = '/raid_sda/yfl/codebase/VL-T5-REG/VL-T5/snap/' + args.dataset + '/' + \\\n",
    "    #                    'vlt5_ofa_mmi_dialog_sp_training_threshold_0.5_use_region_feature' + '/' + '5e-05' + '/' + \"LAST\"\n",
    "    # args.bad_res_path = './REG_mmi_refcocog_vlt5_bad_sent_threshold_0.5_with_bbox.json'\n",
    "    args.mode = 'val'\n",
    "    args.distributed = False\n",
    "    # print(\"===============\")\n",
    "    # print(\"test threshold is {}\".format(args.test_threshold))\n",
    "    # print(\"===============\")\n",
    "\n",
    "\n",
    "    # val_loader = get_loader(\n",
    "    #     args,\n",
    "    #     split=split, mode='val', batch_size=args.batch_size,\n",
    "    #     distributed=args.distributed, gpu=args.gpu,\n",
    "    #     workers=args.num_workers,\n",
    "    #     topk=args.train_topk,\n",
    "    # )\n",
    "    refer = REFER(args.dataset, args.dataset_split, verbose=True)\n",
    "    reg_dataset = RefCOCOGenerationFineTuneDataset(\n",
    "        refer=refer,\n",
    "        split=split,\n",
    "        # raw_dataset=_dset,\n",
    "        rank=args.gpu,\n",
    "        topk=args.train_topk,\n",
    "        verbose=True,\n",
    "        args=args,\n",
    "        mode='val',\n",
    "        task='reg',\n",
    "    )\n",
    "    val_loader = get_loader(\n",
    "        dataset=reg_dataset,\n",
    "        split=split,\n",
    "        mode='val',\n",
    "        task='reg',\n",
    "        batch_size=args.batch_size,\n",
    "        workers=args.num_workers,\n",
    "        distributed=args.distributed,\n",
    "    )\n",
    "\n",
    "    # val_loader = get_loader(\n",
    "    #     args,\n",
    "    #     refer=refer,\n",
    "    #     split=split, mode='val', batch_size=args.batch_size,\n",
    "    #     distributed=False, gpu=args.gpu,\n",
    "    #     workers=4,\n",
    "    #     topk=args.valid_topk,\n",
    "    # )\n",
    "\n",
    "\n",
    "    trainer = Trainer(args, train=False)\n",
    "\n",
    "    # data = json.dumps(results)\n",
    "    # with open('refcoco+_testB', 'w') as f:\n",
    "    #     f.write(data)\n",
    "    #\n",
    "    # print(results)\n",
    "\n",
    "    Score, results = trainer.evaluate(val_loader)\n",
    "\n",
    "    # print(len(Score['CIDErs']))\n",
    "    # if save:\n",
    "    #     i = 0\n",
    "    #     for item in results:\n",
    "    #         item['cider'] = Score['CIDErs'][i]\n",
    "    #         item['meteor'] = Score['METEORs'][i]\n",
    "    #         i = i+1\n",
    "    #\n",
    "    #     data = json.dumps(results)\n",
    "    #     if mmi:\n",
    "    #         with open('result/'+args.dataset+'_'+split+'_mmi.json', 'w') as f:\n",
    "    #             f.write(data)\n",
    "    #     else:\n",
    "    #         with open('result/'+args.dataset+'_'+split+'.json', 'w') as f:\n",
    "    #             f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"vlt5_ofa_dialog_sp_training_one_model_with_new_badsents\"\n",
    "test(dataset='refcoco+', split='testA', task=task, lr='5e-06', epoch=\"13\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (default, Sep 28 2021, 16:10:42) \n[GCC 9.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
